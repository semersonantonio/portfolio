setwd("~/Desktop/Portfolio/Fazer/PrevisaoPosImplante")
# Problema de negócio: Crie um modelo capaz de prever o tempo de sobrevivência
# do paciente, a partir das suas variáveis (marcadores), 1 ano após receber um transplante
# Pacotes
library(dplyr)
library(ggcorrplot)
library(caret)
library(tidyr)
library(DiagrammeR)
library(forecast)
library(nnet)
library(xgboost)
library(Metrics)
# Carga os dados
dados <- read.csv("dados/dataset.csv", header = TRUE, na.strings = c(""))
dim(dados)
## Análise Exploratória ##
View(dados)
str(dados)
# Exploração das variáveis numéricas
hist(dados$AGE, main = "Distribuição de Idade dos Pacientes", xlab = "Idade")
hist(dados$AGE_DON, main = "Distribuição da Idade dos Doadores", xlab = "Idade do Doador")
hist(dados$PTIME, main = "Tempo de Sobrevivência dos Pacientes", xlab = "Tempo (dias)")
hist(dados$DAYSWAIT_CHRON, main = "Tempo de Espera dos Pacientes", xlab = "Tempo de Espera")
hist(dados$FINAL_MELD_SCORE, main = "Score MELD Final", xlab = "Score MELD")
# Análise das variáveis categóricas
dados$DIAB <- as.factor(dados$DIAB)
table(dados$DIAB)
dados$PSTATUS <- as.factor(dados$PSTATUS)
table(dados$PSTATUS)
# Transforma as variáveis categóricas em fator
dados$GENDER <- as.factor(dados$GENDER)
dados$GENDER_DON <- as.factor(dados$GENDER_DON)
table(dados$GENDER)
table(dados$GENDER_DON)
dados$REGION <- as.factor(dados$REGION)
table(dados$REGION)
dados$TX_Year <- as.factor(dados$TX_Year)
table(dados$TX_Year)
dados$MALIG <- as.factor(dados$MALIG)
table(dados$MALIG)
dados$HIST_CANCER_DON <- as.factor(dados$HIST_CANCER_DON)
table(dados$HIST_CANCER_DON)
## Pré-processamento ##
# Filtrando os pacientes com tempo de sobrevivência maior que 365 dias
dados1 <- dados %>%
filter(PTIME > 365) %>%
mutate(PTIME = (PTIME - 365))
dim(dados1)
# Filtrando pacientes com tempo de sobrevivência menor ou igual a 1095 dias
dados2 <- dados1 %>%
filter(PTIME <= 1095)
dim(dados2)
View(dados2)
# Separando variáveis numéricas e categóricas
dados_num <- dados2 %>% dplyr::select_if(is.numeric)
dim(dados_num)
dados_fator <- dados2[,unlist(lapply(dados2, is.factor))]
dim(dados_fator)
# Correlação entre as variáveis numéricas
df_corr <- round(cor(dados_num, use = "complete.obs"), 2)
ggcorrplot(df_corr)
# Padronização das variáveis numéricas
dados_num_norm <- scale(dados_num)
# Combinação em um novo dataframe com as variáveis categóricas
dados_final <- cbind(dados_num_norm, dados_fator)
dim(dados_final)
View(dados_final)
# Divisão em treino e teste
set.seed(1)
index <- sample(1:nrow(dados_final), dim(dados_final)[1]*.7)
dados_treino <- dados_final[index,]
dados_teste <- dados_final[-index,]
# Remove os registros de 2001 e 2002 (primeiros anos da coleta)
dados_treino <- dados_treino %>%
filter(TX_Year != 2001) %>%
filter(TX_Year != 2002)
dados_teste <- dados_teste %>%
filter(TX_Year != 2001) %>%
filter(TX_Year != 2002)
# Criando o diagrama de fluxo
grViz("
digraph fluxo_preprocessamento {
# Definição dos nós do fluxo
node [shape=box, style=filled, fillcolor=lightblue, fontname=Arial]
A [label='Converter Variáveis Categóricas']
B [label='Filtrar Sobrevivência > 365 dias']
C [label='Filtrar Sobrevivência <= 1095 dias']
D [label='Separar Variáveis Numéricas e Categóricas']
E [label='Calcular Correlações']
F [label='Normalizar Variáveis Numéricas']
G [label='Combinar Dados Processados']
H [label='Dividir em Treino e Teste']
I [label='Remover Registros de 2001 e 2002']
# Conexões entre os nós
A -> B
B -> C
C -> D
D -> E
E -> F
F -> G
G -> H
H -> I
}
")
## Modelagem Preditiva ##
# Padronizando os dados de treino e teste de forma separada
set.seed(1)
index <- sample(1:nrow(dados2), dim(dados2)[1]*.7)
dados_treino <- dados2[index,]
dados_teste <- dados2[-index,]
# Separando as variáveis numéricas e categóricas em treino
dados_treino_num <- dados_treino %>% dplyr::select_if(is.numeric)
dados_treino_fator <- dados_treino[,unlist(lapply(dados_treino, is.factor))]
dim(dados_treino_num)
dim(dados_treino_fator)
# Separando as variáveis numéricas e categóricas em teste
dados_teste_num <- dados_teste %>% dplyr::select_if(is.numeric)
dados_teste_fator <- dados_teste[,unlist(lapply(dados_teste, is.factor))]
dim(dados_teste_num)
dim(dados_teste_fator)
# Padronização treino
dados_treino_num_norm <- scale(dados_treino_num)
dados_treino_final <- cbind(dados_treino_num_norm, dados_treino_fator)
# Padronização teste
dados_teste_num_norm <- scale(dados_teste_num)
dados_teste_final <- cbind(dados_teste_num_norm, dados_teste_fator)
# Filtra 2001 e 2002
dados_treino_final <- dados_treino_final %>%
filter(TX_Year != 2001) %>%
filter(TX_Year != 2002)
dados_teste_final <- dados_teste_final %>%
filter(TX_Year != 2001) %>%
filter(TX_Year != 2002)
View(dados_teste_final)
# Cria o modelo com as variáveis mais importantes
modelo_v1 <- lm(PTIME ~ FINAL_MELD_SCORE +
REGION +
AGE +
GENDER+
GENDER_DON+
LiverSize +
LiverSizeDon  +
MALIG +
TX_Year,
data = dados_treino_final)
summary(modelo_v1)
# Coeficientes
coef_modelo <- summary(modelo_v1)$coefficients
coef_df <- data.frame(
Variable = rownames(coef_modelo),
Coefficient = coef_modelo[, 1],
StdError = coef_modelo[, 2]
)
# Gráfico de coeficientes com intervalo de confiança
ggplot(coef_df, aes(x = Coefficient, y = reorder(Variable, Coefficient))) +
geom_point() +
geom_errorbarh(aes(xmin = Coefficient - 1.96 * StdError, xmax = Coefficient + 1.96 * StdError), height = 0.2) +
labs(title = "Coeficientes do Modelo de Regressão", x = "Coeficiente", y = "Variável") +
theme_minimal()
## Avaliação do modelo
# Com dados de treino
modelo_v1_pred_1 = predict(modelo_v1, newdata = dados_treino_final)
accuracy(modelo_v1_pred_1, dados_treino_final$PTIME)
# Com dados de teste
modelo_v1_pred_2 = predict(modelo_v1, newdata = dados_teste_final)
accuracy(modelo_v1_pred_2, dados_teste_final$PTIME)
# Distribuição do erro de validação
par(mfrow = c(1,1))
residuos <- dados_teste_final$PTIME - modelo_v1_pred_2
hist(residuos, xlab = "Resíduos", main = "Sobreviventes de 1 a 3 Anos")
# Escala dos dados
variaveis_amostra <- c("PTIME",
"FINAL_MELD_SCORE",
"REGION",
"AGE",
"GENDER",
"GENDER_DON",
"LiverSize",
"LiverSizeDon",
"MALIG",
"TX_Year")
# Removemos valores NA das variáveis para aplicar o unscale
dados_unscale <- na.omit(dados2[,variaveis_amostra])
# Retorna os dados unscale
dados_final_unscale <- dados_unscale[-index,] %>%
filter(TX_Year!= 2001) %>%
filter(TX_Year!= 2002)
# Histograma dos dados em formato original
previsoes = predict(modelo_v1, newdata = dados_final_unscale)
hist(previsoes)
accuracy(previsoes, dados_final_unscale$PTIME)
# Calcular os resíduos (erro de previsão) com base no modelo ajustado
residuos <- dados_teste_final$PTIME - modelo_v1_pred_2
# Gráfico de histograma dos resíduos
hist(residuos,
xlab = "Resíduos",
main = "Distribuição dos Resíduos",
col = "gray",
border = "black",
breaks = 20)
abline(v = 0, col = "red", lwd = 2)
# Calcular as previsões para os dados de treino
modelo_v1_pred_1 <- predict(modelo_v1, newdata = dados_treino_final)
# Calcular as previsões para os dados de teste
modelo_v1_pred_2 <- predict(modelo_v1, newdata = dados_teste_final)
# Métricas de precisão para os dados de treino
mae_train <- mae(dados_treino_final$PTIME, modelo_v1_pred_1)
rmse_train <- rmse(dados_treino_final$PTIME, modelo_v1_pred_1)
r2_train <- cor(dados_treino_final$PTIME, modelo_v1_pred_1)^2
# Métricas de precisão para os dados de teste
mae_test <- mae(dados_teste_final$PTIME, modelo_v1_pred_2)
rmse_test <- rmse(dados_teste_final$PTIME, modelo_v1_pred_2)
r2_test <- cor(dados_teste_final$PTIME, modelo_v1_pred_2)^2
# Exibir as métricas de precisão
cat("Métricas de Precisão para Dados de Treino:\n")
cat("MAE:", mae_train, "\n")
cat("RMSE:", rmse_train, "\n")
cat("R²:", r2_train, "\n")
cat("\nMétricas de Precisão para Dados de Teste:\n")
cat("MAE:", mae_test, "\n")
cat("RMSE:", rmse_test, "\n")
cat("R²:", r2_test, "\n")
# Criar um dataframe com as métricas
metricas <- data.frame(
Metric = rep(c("MAE", "RMSE", "R²"), 2),
Value = c(mae_train, rmse_train, r2_train, mae_test, rmse_test, r2_test),
Dataset = rep(c("Treino", "Teste"), each = 3)
)
# Gráfico de barras com ggplot
ggplot(metricas, aes(x = Metric, y = Value, fill = Dataset)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Métricas de Precisão do Modelo", x = "Métrica", y = "Valor") +
scale_fill_manual(values = c("Treino" = "red", "Teste" = "gray")) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 0, hjust = 0.5))
# Obter os valores reais e os valores previstos
valores_reais <- dados_teste_final$PTIME
valores_previstos <- modelo_v1_pred_2
# Criar um dataframe com os valores reais e previstos
df_comparacao <- data.frame(
Reais = valores_reais,
Previstos = valores_previstos
)
# Criar o gráfico de dispersão
ggplot(df_comparacao, aes(x = Previstos, y = Reais)) +
geom_point(color = "gray", alpha = 0.6) +
geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
labs(title = "Valores Reais vs. Valores Previstos", x = "Valores Previstos", y = "Valores Reais") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
## Modelo XGBoots ##
# Divisão dos dados em treino e teste
index <- sample(1:nrow(dados_final), dim(dados_final)[1]*.7)
dados_treino <- dados_final[index,]
dados_teste <- dados_final[-index,]
# Remove 2001 e 2002
dados_treino <- dados_treino %>%
filter(TX_Year != 2001) %>%
filter(TX_Year != 2002)
dados_teste <- dados_teste %>%
filter(TX_Year != 2001) %>%
filter(TX_Year != 2002)
# Separando variáveis numéricas e categóricas em treino
dados_treino_num <- dados_treino %>% dplyr::select_if(is.numeric)
dados_treino_fator <- dados_treino[,unlist(lapply(dados_treino, is.factor))]
# Separando variáveis numéricas e categóricas em teste
dados_teste_num <- dados_teste %>% dplyr::select_if(is.numeric)
dados_teste_fator <- dados_teste[,unlist(lapply(dados_teste, is.factor))]
# Padronização dos dados numéricos
dados_treino_num_norm <- scale(dados_treino_num)
dados_teste_num_norm <- scale(dados_teste_num)
# Combina dados normalizados com variáveis categóricas
dados_treino_final <- cbind(dados_treino_num_norm, dados_treino_fator)
dados_teste_final <- cbind(dados_teste_num_norm, dados_teste_fator)
# Converte para formato de matriz para XGBoost
X_train <- as.matrix(dados_treino_num_norm)
y_train <- dados_treino$PTIME
X_test <- as.matrix(dados_teste_num_norm)
y_test <- dados_teste$PTIME
# Define os parâmetros do XGBoost
parametros <- list(
objective = "reg:squarederror",
booster = "gbtree",
eta = 0.1,
max_depth = 6,
subsample = 0.8,
colsample_bytree = 0.8
)
# Treina o XGBoost
# Criando as matrizes de treino e teste
dtrain <- xgb.DMatrix(data = X_train, label = y_train)
dtest <- xgb.DMatrix(data = X_test, label = y_test)
# Definindo o watchlist
watchlist <- list(train = dtrain, eval = dtest)
# Treinando o modelo XGBoost com early stopping
modelo_xgb <- xgb.train(
data = dtrain,
max.depth = 5,
eta = 0.1,
nrounds = 200,
early_stopping_rounds = 10,
eval_metric = "rmse",
watchlist = watchlist
)
# Previsões com dados de treino e teste
pred_treino <- predict(modelo_xgb, newdata = X_train)
pred_teste <- predict(modelo_xgb, newdata = X_test)
# Avaliação do modelo nos dados de treino
rmse_treino <- rmse(y_train, pred_treino)
mae_treino <- mae(y_train, pred_treino)
mse_treino <- mse(y_train, pred_treino)
r2_treino <- 1 - sum((y_train - pred_treino)^2) / sum((y_train - mean(y_train))^2)
# Avaliação do modelo nos dados de teste
rmse_teste <- rmse(y_test, pred_teste)
mae_teste <- mae(y_test, pred_teste)
mse_teste <- mse(y_test, pred_teste)
r2_teste <- 1 - sum((y_test - pred_teste)^2) / sum((y_test - mean(y_test))^2)
# Exibindo as métricas
cat("Avaliação nos Dados de Treino:\n")
cat("RMSE:", rmse_treino, "\n")
cat("MAE:", mae_treino, "\n")
cat("MSE:", mse_treino, "\n")
cat("R²:", r2_treino, "\n")
cat("\nAvaliação nos Dados de Teste:\n")
cat("RMSE:", rmse_teste, "\n")
cat("MAE:", mae_teste, "\n")
cat("MSE:", mse_teste, "\n")
cat("R²:", r2_teste, "\n")
# Visualiza os resíduos em teste
residuos <- y_test - pred_teste
hist(residuos, xlab = "Resíduos", main = "Distribuição dos Resíduos - XGBoost")
## Tabela comparativa para os dois modelos ##
# Função para calcular o RMSE, MAE, MSE e R²
calcular_metricas <- function(predicao, reais) {
rmse_valor <- sqrt(mean((predicao - reais)^2))
mae_valor <- mean(abs(predicao - reais))
mse_valor <- mean((predicao - reais)^2)
r2_valor <- 1 - sum((reais - predicao)^2) / sum((reais - mean(reais))^2)
return(c(RMSE = rmse_valor, MAE = mae_valor, MSE = mse_valor, R2 = r2_valor))
}
# Cálculo das métricas para o modelo de Regressão Linear (LM)
# Dados de treino
metricas_lm_treino <- calcular_metricas(modelo_v1_pred_1, dados_treino_final$PTIME)
# Dados de teste
metricas_lm_teste <- calcular_metricas(modelo_v1_pred_2, dados_teste_final$PTIME)
# Cálculo das métricas para o modelo XGBoost
# Dados de treino
metricas_xgb_treino <- calcular_metricas(pred_treino, y_train)
# Dados de teste
metricas_xgb_teste <- calcular_metricas(pred_teste, y_test)
# Criando a tabela comparativa
tabela_comparativa <- data.frame(
Modelo = c("Regressão Linear", "XGBoost"),
RMSE_Treino = c(metricas_lm_treino["RMSE"], metricas_xgb_treino["RMSE"]),
MAE_Treino = c(metricas_lm_treino["MAE"], metricas_xgb_treino["MAE"]),
MSE_Treino = c(metricas_lm_treino["MSE"], metricas_xgb_treino["MSE"]),
R2_Treino = c(metricas_lm_treino["R2"], metricas_xgb_treino["R2"]),
RMSE_Test = c(metricas_lm_teste["RMSE"], metricas_xgb_teste["RMSE"]),
MAE_Test = c(metricas_lm_teste["MAE"], metricas_xgb_teste["MAE"]),
MSE_Test = c(metricas_lm_teste["MSE"], metricas_xgb_teste["MSE"]),
R2_Test = c(metricas_lm_teste["R2"], metricas_xgb_teste["R2"])
)
# Exibe a tabela comparativa
View(tabela_comparativa)
# Transformando a tabela para formato longo
tabela_comparativa_long <- tabela_comparativa %>%
gather(key = "Métrica", value = "Valor", -Modelo)
# Gráfico para cada métrica
ggplot(tabela_comparativa_long, aes(x = Modelo, y = Valor, fill = Modelo)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~Métrica, scales = "free_y") +
theme_minimal() +
labs(title = "Comparação de Métricas entre Modelos", y = "Valor", x = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
